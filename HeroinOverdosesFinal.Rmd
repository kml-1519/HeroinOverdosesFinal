---
title: "Addressing Mesa, Arizona's Heroin Epidemic"
author: "Kayla Lumpkin and Sam Hausner-Levine"
date: "12/13/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: "hide"
    code_download: true
---

## Table of Contents
1. Introduction 
2. Data Used 
3. Map of Heroin Overdoses in Point Form
4. Map of Heroin Overdoses joined to the Fishnet Grid 
5. Small Multiple Map of Risk Factors in the Fishnet 
6. Local Moran's I related small multiple map of Overdoses
7. Small Multiple Scatterplot with Correlations 
8. Histogram of Dependent Variable 
10. A small multiple map of model errors by random k-fold and spatial cross validation
11. A table of MAE and standard deviation MAE by regression.
12. A table of raw errors by race context for a random k-fold vs. spatial cross validation regression
13. A map comparing kernel density to risk predictions for the next year’s crime
    + A bar plot making this comparison
15. Conclusion 

# Introduction 

Though there are many biases inherent in the way the City of Chicago is policed, the model created below seeks to predict the risk of reported non-aggravated sexual assaults in 2018 based on data from 2017. 

While safety is rarely maintained by relying exclusively on police, the areas identified as high risk for assaults could be targeted for alternative forms of protection including improved lighting, increased interventions in alcohol use, and city funded education programs geared towards youth to inform them of consent and psychological services. 

```{r setup, message=FALSE, warning=FALSE, include=TRUE, results='hide'}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(mapview)

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

# Data Used 
We primarily rely on data gathered from Chicago's Open data portal and the U.S. Census in the code blocks below. 

```{r pulling data, message=FALSE, warning=FALSE, include=TRUE, results='hide'}

policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/fthy-xz3r?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = dist_num)
  
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/aerh-rz74?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = beat_num)

bothPoliceUnits <- rbind(mutate(policeDistricts, Legend = "Police Districts"), 
                         mutate(policeBeats, Legend = "Police Beats"))

chicagoBoundary <- 
  st_read(file.path(root.dir,"/Chapter5/chicagoBoundary.geojson")) %>%
  st_transform('ESRI:102271')

fishnet <- 
  st_make_grid(chicagoBoundary,
               cellsize = 500, 
               square = TRUE) %>%
  .[chicagoBoundary] %>%            # <- MDH Added
  st_sf() %>%
  mutate(uniqueID = rownames(.))

Sexual.Assaults <- read.socrata("https://data.cityofchicago.org/Public-Safety/Crimes-2017/d62x-nvdr") %>% 
    filter(Primary.Type == "CRIM SEXUAL ASSAULT" & Description == "NON-AGGRAVATED") %>%
    mutate(x = gsub("[()]", "", Location)) %>%
    separate(x,into= c("Y","X"), sep=",") %>%
    mutate(X = as.numeric(X),Y = as.numeric(Y)) %>% 
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant")%>%
    st_transform('ESRI:102271') %>% 
    distinct()

```
# Map of Sexual Assaults in Point Form
The point and density maps of sexual assault incidents below reveals that a great number of assaults occur in the central part of chicago. After consulting a map of Chicago neighborhoods, the loop, near northside, and near south side areas seem to be the sites with the most reported non-aggravated sexual assaults. 

```{r pointmap, message=FALSE, warning=FALSE, results='hide'}
# uses grid.arrange to organize independent plots
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = Sexual.Assaults, colour="red", size=0.1, show.legend = "point") +
  labs(title= "Sexual Assaults, Chicago - 2017") +
  mapTheme(title_size = 14),

ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(Sexual.Assaults)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of sexual Assaults") +
  mapTheme(title_size = 14) + theme(legend.position = "none"))

```

# Map of Sexual Assaults joined to the Fishnet Grid 

The fishnet grid below shows the count of sexual assaults by grid cell. Notably, the yellow cell has a very high count of assaults, denoting a potential hotspot.

```{r fishnet,message=FALSE, warning=FALSE, results='hide'}
crime_net <- 
  dplyr::select(Sexual.Assaults) %>% 
  mutate(countAssaults = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countAssaults = replace_na(countAssaults, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), size=nrow(fishnet), replace = TRUE))

#map
ggplot() +
  geom_sf(data = crime_net, aes(fill = countAssaults)) +
  scale_fill_viridis() +
  labs(title = "Count of Sexual Assaults for the Chicago fishnet") +
  mapTheme()

```


# Small Multiple Map of Risk Factors in the Fishnet

Nine risk factors were gathered to include in my analysis, including: 
1. Schools
2. Abandoned Cars
3. vacant and abandoned buildings
4. affordable rental housing developments
5. 311 reports of Graffiti Removal Requests
6. 311 reports of street lights out
7. sanitation complaints
8. Location of retail stores that sell liquor to go
9. Places of businesses with liquor approved permits

The risk factors above were chosen because alcohol use often plays a factor in reported sexual assaults, as perpetrators are likely to target people under the influence of alcohol, so places that sell liquor or businesses that are permitted to sell alcohol might be the site of reported violations. Additionally, reported assaults could be more prevalent in areas with deteriorating Features such as broken street lights, sanitation issues, or abandoned cars and buildings. Finally, I also thought that assaults might commonly occur in apartment buildings (of which only affordable units were available on Chicago's Open data website) and/or schools.

```{r riskfactors, fig.height=10, fig.width=16, message=FALSE, warning=FALSE, results='hide'}
#Data is downloaded; year and coordinates are created and the latter converted to sf. 

#The data is then projected and a Legend field is added to label the risk factor. This allows each to be rbind into one dataset for small multiple mapping, as shown in Figure 5.5.

#The graffiti code block is the first where we have seen the %in% operator, which enables filter to take inputs from a list rather than chaining together several ‘or’ (|) statements.

#filter(where_is_the_graffiti_located_ %in% c("Front", "Rear", "Side")) %>%

schools <- 
  read.socrata("https://data.cityofchicago.org/Education/CPS-Schools-2013-2014-Academic-Year/c7jj-qjvh") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Schools")

abandonCars <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Abandoned-Vehicles/3c9v-pnva") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2017") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Abandoned_Cars")
  
abandonBuildings <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Vacant-and-Abandoned-Building/7nii-7srd") %>%
    mutate(year = substr(date_service_request_was_received,1,4)) %>%  filter(year == "2017") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Abandoned_Buildings")

affordableRentals <- 
  read.socrata("https://data.cityofchicago.org/Community-Economic-Development/Affordable-Rental-Housing-Developments/s6ha-ppgi") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Affordable_Rental_Developments")

graffiti <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Graffiti-Removal-Historical/hec5-y4x5") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2017") %>%
    filter(where_is_the_graffiti_located_ %in% c("Front", "Rear", "Side")) %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Graffiti")

streetLightsOut <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Street-Lights-All-Out/zuxi-7xem") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2017") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Street_Lights_Out")

sanitation <-
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Sanitation-Code-Complaints-Hi/me59-5fac") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2017") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Sanitation")

liquorRetail <- 
  read.socrata("https://data.cityofchicago.org/resource/nrmj-3kcf.json") %>%  
    filter(business_activity == "Retail Sales of Packaged Liquor") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Liquor_Retail")

Buis_LiqLicenses2 <-
  read.socrata("https://data.cityofchicago.org/resource/r5kz-chrr.json") %>%
    mutate(year = substr(date_issued,1,4)) %>% filter(year <= "2018") %>%
    filter(business_activity == "Consumption of Liquor on Premises") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Buisnesses_w_Liquor_License")

neighborhoods <- 
  st_read("https://raw.githubusercontent.com/blackmad/neighborhoods/master/chicago.geojson") %>%
  st_transform(st_crs(fishnet)) 

#Count of risk factors by grid cell by joining a long form layer of crime events to the vars_net fishnet. 

vars_net <- rbind(schools,abandonCars,streetLightsOut,Buis_LiqLicenses2,abandonBuildings,
        liquorRetail, graffiti, sanitation,affordableRentals) %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  summarize(count = n()) %>%
  full_join(fishnet, by = "uniqueID") %>%
  spread(Legend, count, fill=0) %>%
  st_sf() %>%
  dplyr::select(-`<NA>`) %>%
  na.omit() %>%
  ungroup()

vars_net.long <- 
  gather(vars_net, Variable, value, -geometry, -uniqueID)

vars <- unique(vars_net.long$Variable)
mapList <- list()

for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange,c(mapList, ncol=3, top="Risk Factors by Fishnet"))

```

# Local Moran's I related small multiple map of Sexual Assaults

The Local Moran’s I statistical test allows us to visualize  the spatial autocorrelation of  model errors at the most local level. With this, I am able to see that there are are statistically significant sexual assault hot spots by the loop and previously identified areas. These hotspot areas, with a lot of clustering and a high Moran's value, allows us to seemingly select these areas as high risk. 
```{r localMorans, fig.height=10, fig.width=16, message=FALSE, warning=FALSE, results='hide'}
#Setting up Nearest Neighbor

st_c <- st_coordinates
st_coid <- st_centroid

vars_net <-
  vars_net %>%
    mutate(
      Abandoned_Buildings.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(abandonBuildings),3),
      Abandoned_Cars.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(abandonCars),3),
      Graffiti.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(graffiti),3),
      Liquor_Retail.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(liquorRetail),3),
      Street_Lights_Out.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(streetLightsOut),3),
      Schools.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(schools),3),
      Abandoned_Rentals.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(affordableRentals),3),
      Buis_Liquor.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(Buis_LiqLicenses2),3),
      Sanitation.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(sanitation),3))

#pLot 
#Note the use of select and ends_with to map only the nearest neighbor features.

vars_net.long.nn <- 
  dplyr::select(vars_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

vars <- unique(vars_net.long.nn$Variable)
mapList <- list()

for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long.nn, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange,c(mapList, ncol = 3, top = "Nearest Neighbor risk Factors by Fishnet"))

## Join NN feature to fishnet

loopPoint <-
  filter(neighborhoods, name == "Loop") %>%
  st_centroid()

vars_net$loopDistance =
  st_distance(st_centroid(vars_net),loopPoint) %>%
  as.numeric()

### Join in areal data

final_net <-
  left_join(crime_net, st_drop_geometry(vars_net), by="uniqueID") 

final_net <-
  st_centroid(final_net) %>%
    st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
    st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
      st_sf() %>%
  na.omit()

#LOcal Moran's 

## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)

# print(final_net.weights, zero.policy=TRUE)

#relatively high values of I represent strong and statistically significant evidence of local clustering.

# join local Moran's I results to fishnet
local_morans <- localmoran(final_net$countAssaults, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(Assault_Count = countAssaults, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)

##plotting
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 14) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Sexual Assaults"))
  

```


# Small Multiple Scatterplot with Correlations

Based on the hotspots identified in the previous code block,  assault.isSig allows us to ask whether a cell is in a hotspot for assault, and assault.isSig.dist is the distance from a cell to its nearest hotspot.
The correlation plots then detail correlation for each selected feature with the count of sexual assaults. From the results, it is evident that the nearest neighbor features are a better way to determine how sexual assaults are observed.

```{r scatterplots, fig.height=16, fig.width=16, message=FALSE, warning=FALSE, results='hide'}
# generates warning from NN
final_net <- final_net %>% 
  mutate(assault.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>%
  mutate(assault.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           assault.isSig == 1))), 
                       k = 1))
ggplot() +
      geom_sf(data = final_net, aes(fill=assault.isSig.dist), colour=NA) +
      scale_fill_viridis(name="Distance") +
      labs(title="Distance to sig sexual assault hotspots") +
      mapTheme()
#This map shows distance to a significant hotspot as a variable

#correlation plots
correlation.long <-
  st_drop_geometry(final_net) %>%
    dplyr::select(-uniqueID, -cvID, -loopDistance, -name, -District) %>%
    gather(Variable, Value, -countAssaults)

correlation.cor <-
  correlation.long %>%
    group_by(Variable) %>%
    summarize(correlation = cor(Value, countAssaults, use = "complete.obs"))
    
ggplot(correlation.long, aes(Value, countAssaults)) +
  geom_point(size = 0.1) +
  geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf) +
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  labs(title = "Sexual Assault count as a function of risk factors") +
  plotTheme()

```

# Histogram of Dependent Variable 

Next, I created the reg.vars and reg.ss.vars features, which differ in that reg. vars does not include spatial features and the other does. The requested histogram below shows that the majority of counted sexual assaults fall within the 0 to 1 range.

```{r histogram, message=FALSE, warning=FALSE, include=TRUE, results='hide'}
reg.vars <- c("Schools.nn","Buis_Liquor.nn", "Abandoned_Rentals.nn", "Abandoned_Buildings.nn", "Abandoned_Cars.nn", "Graffiti.nn", 
              "Liquor_Retail.nn", "Street_Lights_Out.nn", "Sanitation.nn", 
              "loopDistance")

reg.ss.vars <- c("Schools.nn","Buis_Liquor.nn","Abandoned_Buildings.nn", "Abandoned_Cars.nn", "Graffiti.nn", "Liquor_Retail.nn", "Street_Lights_Out.nn", "Sanitation.nn", "loopDistance", "assault.isSig", "assault.isSig.dist")

hist(final_net$countAssaults)

#Results show OLS regression is inappropriate in this case 
```

# A small multiple map of model errors by random k-fold and spatial cross validation

Next, the small multiple map below shows cross validation across four regressions. It is evident that spatial, neighborhood based regressions produce lower errors, but are slightly less clustered than random-k-fold regressions. This allows us to conclude there is a shared experience of sexual assaults across Chicago, and accounting for it improves the model. 

```{r errors, fig.height=8, fig.width=8, message=FALSE, warning=FALSE, results='hide'}

# CV function
crossValidate <- function(dataset, id, dependentVariable, indVariables) {
  
  allPredictions <- data.frame()
  cvID_list <- unique(dataset[[id]])
  
  for (i in cvID_list) {
    
    thisFold <- i
    cat("This hold out fold is", thisFold, "\n")
    
    fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
      dplyr::select(id, geometry, indVariables, dependentVariable)
    fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
      dplyr::select(id, geometry, indVariables, dependentVariable)
    
    regression <- glm(paste0(dependentVariable,"~."), family = "poisson", 
    data = fold.train %>% dplyr::select(-geometry, -id))
    
    thisPrediction <- 
      mutate(fold.test, Prediction = predict(regression, fold.test, type = "response"))
    
    allPredictions <-
      rbind(allPredictions, thisPrediction)
    
  }
  return(st_sf(allPredictions))
}

reg.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countAssaults",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countAssaults, Prediction, geometry)

reg.ss.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countAssaults",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = cvID, countAssaults, Prediction, geometry)
  
reg.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countAssaults",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = name, countAssaults, Prediction, geometry)

reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "name",
  dependentVariable = "countAssaults",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countAssaults, Prediction, geometry)

reg.summary <- 
  rbind(
    mutate(reg.cv,           Error = Prediction - countAssaults,
                             Regression = "Random k-fold CV: Just Risk Factors"),
                             
    mutate(reg.ss.cv,        Error = Prediction - countAssaults,
                             Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countAssaults,
                             Regression = "Spatial LOGO-CV: Just Risk Factors"),
                             
    mutate(reg.ss.spatialCV, Error = Prediction - countAssaults,
                             Regression = "Spatial LOGO-CV: Spatial Process")) %>%
    st_sf() 

#The code block below, error_by_reg_and_fold calculates and visualize MAE for each fold across each regression..

#LOGO-CV assumes the local spatial process from all other neighborhoods generalizes to the hold-out. 


error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countAssaults, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
    facet_wrap(~Regression) +  
    geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
         x="Mean Absolute Error", y="Count") +
    plotTheme()


```

# A table of MAE and standard deviation MAE by regression

The table below builds on error_by_reg_and_fold to calculate the mean and standard deviation in errors by regression. The mean of reported sexual assaults in Chicago 2017 was 0.4403219, which is somewhat near the mean for the spatial LOGO-CV process. Though for random k-fold the spatial aspect does not seem to play a role.

```{r MAE, message=FALSE, warning=FALSE, include=TRUE}
#table

st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
    summarize(Mean_MAE = round(mean(MAE), 2),
              SD_MAE = round(sd(MAE), 2)) %>%
  kable(caption = "MAE by Regression") %>%
    kable_styling("striped", full_width = F) %>%
    row_spec(2, color = "black", background = "#FDE725FF") %>%
    row_spec(4, color = "black", background = "#FDE725FF") 

#For intuition on how severe these errors are, compare them to the observed mean countAssaults
mean(final_net$countAssaults)

#visualize the LOGO-CV errors spatially

#str_detect in the filter operation to pull out just the LOGO-CV regression errors. These maps visualize where the higher errors occur when the local spatial process is not accounted for. Not surprisingly, the largest errors are in the hotspot locations.

error_by_reg_and_fold %>%
  filter(str_detect(Regression, "LOGO")) %>%
  ggplot() +
    geom_sf(aes(fill = MAE)) +
    facet_wrap(~Regression) +
    scale_fill_viridis() +
    labs(title = "Sexual Assault errors by LOGO-CV Regression") +
    mapTheme() + theme(legend.position="bottom")

```

# A table of raw errors by race context for a random k-fold vs. spatial cross validation regression

The table below shows mean error for each neighborhood in the context of racial demographics.The models both have close errors in both racial contexts. However, just risk factors overpredicts the risk of sexual assaults in white areas, while  the spatial process overpredicts the likelihood of sexual assaults in majority non-white areas. 

```{r raw, message=FALSE, warning=FALSE, include=TRUE}
#Pulling Census Race Data 

census_api_key("1d63e5e6e661f6fd556f9671502bf3879e3a9fd3", overwrite = TRUE)

tracts18 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E"), 
          year = 2018, state=17, county=031, geometry=T) %>%
  st_transform('ESRI:102271')  %>% 
  dplyr::select(variable, estimate, GEOID) %>%
  spread(variable, estimate) %>%
  rename(TotalPop = B01001_001,
         NumberWhites = B01001A_001) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority_White", "Majority_Non_White")) %>%
  .[neighborhoods,]

reg.summary %>% 
  filter(str_detect(Regression, "LOGO")) %>%
    st_centroid() %>%
    st_join(tracts18) %>%
    na.omit() %>%
      st_drop_geometry() %>%
      group_by(Regression, raceContext) %>%
      summarize(mean.Error = mean(Error, na.rm = T)) %>%
      spread(raceContext, mean.Error) %>%
      kable(caption = "Mean Error by neighborhood racial context") %>%
        kable_styling("striped", full_width = F)  
```

# A map and bar plot comparing kernel density to risk predictions for the next year’s crime
The kernel density map below relies soley on spatial process to aid in the prediction of sexual assaults based on a 1000 ft search radius. The map shows risk is relatively similar in hotspots. The bar plot shows the kernel density model and risk prediction predict evenly in the highest risk category, with distinctions in lower risk categories. 

```{r kernel density comparison, message=FALSE, warning=FALSE, results='hide'}
#The code block below creates a Kernel density map with a 1000 foot search radius using the spatstat package. 
#as.ppp converts burglary coordinates to a ppp class. 
#The density function creates the Kernel density. 

# demo of kernel width
sassault_ppp <- as.ppp(st_coordinates(Sexual.Assaults), W = st_bbox(final_net))
sassault_KD.1000 <- spatstat.core::density.ppp(sassault_ppp, 1000)
sassault_KD.1500 <- spatstat.core::density.ppp(sassault_ppp, 1500)
sassault_KD.2000 <- spatstat.core::density.ppp(sassault_ppp, 2000)
sassault_KD.df <- rbind(
  mutate(data.frame(rasterToPoints(mask(raster(sassault_KD.1000), as(neighborhoods, 'Spatial')))), Legend = "1000 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(sassault_KD.1500), as(neighborhoods, 'Spatial')))), Legend = "1500 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(sassault_KD.2000), as(neighborhoods, 'Spatial')))), Legend = "2000 Ft.")) 

sassault_KD.df$Legend <- factor(sassault_KD.df$Legend, levels = c("1000 Ft.", "1500 Ft.", "2000 Ft."))

ggplot(data=sassault_KD.df, aes(x=x, y=y)) +
  geom_raster(aes(fill=layer)) + 
  facet_wrap(~Legend) +
  coord_sf(crs=st_crs(final_net)) + 
  scale_fill_viridis(name="Density") +
  labs(title = "Kernel density with 3 different search radii") +
  mapTheme(title_size = 14)

#2017 sexual assaults

as.data.frame(sassault_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(Sexual.Assaults, 1500, replace = TRUE), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of 2017 sexual assaults") +
     mapTheme(title_size = 14)

#compare to 2018 sexual assaults 
#download 18 crime data
Sexual.Assaults.18 <- 
  read.socrata("https://data.cityofchicago.org/Public-Safety/Crimes-2018/3i3m-jwuy") %>% 
  filter(Primary.Type == "CRIM SEXUAL ASSAULT" & Description == "NON-AGGRAVATED") %>%
  mutate(x = gsub("[()]", "", Location)) %>%
  separate(x,into= c("Y","X"), sep=",") %>%
  mutate(X = as.numeric(X),
         Y = as.numeric(Y)) %>% 
  na.omit %>%
  st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102271') %>% 
  distinct() %>%
  .[fishnet,]

#compute kernel density on the 2017 sexual assaults

#sassault_KDE_sf converts the density to an sf layer; spatial joins (aggregate) it to the fishnet; 
#converts the density to 100 deciles (ntile); and again to 5 risk categories. Finally, one last spatial join adds the count of observed burglaries in 2018

sassault_KDE_sf <- as.data.frame(sassault_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
  mutate(label = "Kernel Density",
         Risk_Category = ntile(value, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category  <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(Sexual.Assaults.18) %>% mutate(sassCount = 1), ., sum) %>%
    mutate(sassCount = replace_na(sassCount, 0))) %>%
  dplyr::select(label, Risk_Category, sassCount)

head(sassault_KDE_sf)

sassault_risk_sf <-
  filter(reg.summary, Regression == "Spatial LOGO-CV: Spatial Process") %>%
  mutate(label = "Risk Predictions",
         Risk_Category = ntile(Prediction, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(Sexual.Assaults.18) %>% mutate(sassCount = 1), ., sum) %>%
      mutate(sassCount = replace_na(sassCount, 0))) %>%
  dplyr::select(label,Risk_Category, sassCount)

#Making comparisons for 2017 vs 2018

rbind(sassault_KDE_sf, sassault_risk_sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(Sexual.Assaults.18, 3000,replace = TRUE), size = .5, colour = "black") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2017 sexual assault risk predictions; 2018 sexual assaults") +
    mapTheme()

##The bar plot making this comparison

rbind(sassault_KDE_sf, sassault_risk_sf) %>%
  st_set_geometry(NULL) %>% na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(countAssualts = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Rate_of_test_set_crimes = countAssualts / sum(countAssualts)) %>%
    ggplot(aes(Risk_Category,Rate_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_viridis(discrete = TRUE) +
      labs(title = "Risk prediction vs. Kernel density, 2018 Sexual Assaults") +
      plotTheme() + theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```
# Conclusion 

I would not recommend this algorithm to be put in production by police departments. Primarily because of the biases inherent in predicting risk off of already reported harm. Though reported sexual assaults may on the surface seem like one of the few crimes where racism does not play a factor, age, gender dynamics, class and other societal power imbalances likely result in underreported assaults. 

Furthermore, if this model were to be used - it would hopefully be implemented as a tool for intervention before assaults occur in areas that are identified as high risk. 
